{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIProject2-HarshThakkar.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiwlaccYsJnI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "d0e27ece-0036-405d-d20b-7d2daf7d7b23"
      },
      "source": [
        "!pip install quadprog"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: quadprog in /usr/local/lib/python3.6/dist-packages (0.1.7)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from quadprog) (0.29.16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-7OYFKxdFOt"
      },
      "source": [
        "**Course Name : CS6613 Artificial Intelligence**\n",
        "\n",
        "\n",
        "**Project 2 :** Continual learning for robotic perception\n",
        "\n",
        "\n",
        "**Author** : Harsh Thakkar (ht1215@nyu.edu)\n",
        "\n",
        "Continual learning has become essential because real-world data keeps changing and we at any point never have access to the entire dataset from the data distribution. So at an instance, we try to train the model on given training dataset and expect it to perform well on future dataset as result is of course not desirable. When a model is trained on certain dataset, it acquires knowledge from that dataset in and stores in the form of weights and observing similar data it can predict the label or target value associated with this. When this same model observes the data from other distribution, it performs very poorly since stored weights have no idea about the new data distribution. When try to train the same model on new data, all the weights are over-written, that is it gains new knowledge based on new dataset and perform well on new dataset at the cost of performing poorly on the old dataset. This concept is known as \"Catastrophic forgetting\". \n",
        "\n",
        "Continual learning is an approach to human-like thinking. An effort to carry forward previously learned knowledge while learning new tasks. In this notebook, I tried to discuss one of the methods, Gradient episodic memory, discussed in the paper : http://papers.nips.cc/paper/7225-gradient-episodic-memory-for-continual-learning.pdf\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLLlfRpPlxDe"
      },
      "source": [
        "**Approach** \n",
        "\n",
        "Instead of taking batches from the same dataset, in this approach, we take batches from different tasks and instead of training it with (x,y) where x is the feature vector and y is the label, we take (x,t,y) where t is the task number and train the model using this data distribution. While updating the data distribution in this way, there are many unknown challanges that were not present in the prior method. \n",
        "\n",
        "1) Non-IID dataset : Since data continuum in this method depends on the task number, entire data distribution changes when the task number changes.\n",
        "\n",
        "2) Catastrophic forgetting : Learning new tasks overwrites the previously learned weights.\n",
        "\n",
        "3) Transfer learning : When the tasks are related to each other, there is a possibility of transferring previous knowledge to the current tasks for faster learning.\n",
        "\n",
        "\n",
        "**FRAMEWORK**\n",
        "\n",
        "The idea is to feed (x,t) where x is the feature vector and t is the task descriptor and try to predict target vector y. Using of task descriptor is essential since, there is a possibility that in one task a feature vector x corresponds to a vector y and in other task same feature vector corresponds to different target vector. \n",
        "\n",
        "Other than accuracy of the system, it is also important to note the amount of knowledge being transferred to the future tasks and affect of learning new tasks on previous learned tasks. \n",
        "\n",
        "1) Backward transfer : That is the effect of learning current task on previously learned tasks. Positive backward transfer measures how much accuracy of previously learned tasks have been improved because of learning new task and negative backward transfer measures the degradation of performance of previous tasks because of learning new task. \n",
        "\n",
        "2) Forward Transfer : This measures the effect of learning current tasks on future tasks\n",
        "\n",
        "To measure the above mentioned parameters, after learning each tasks t, model is evaluated its test performance on all the T tasks. A matrix is created (R) in which for any entry i,j is the test accuracy of j task after learning i task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRC1EBS2JfuL"
      },
      "source": [
        "This cell loads MNIST dataset from the source and stores in the working dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bl8eV3C5aAT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7e64d78e-d39d-4d2f-fa30-2f94fa970e68"
      },
      "source": [
        "import numpy as np\n",
        "import subprocess\n",
        "import pickle\n",
        "import torch\n",
        "import os\n",
        "\n",
        "mnist_path = \"mnist.npz\"\n",
        "\n",
        "if not os.path.exists(mnist_path):\n",
        "    subprocess.call(\"wget https://s3.amazonaws.com/img-datasets/mnist.npz\", shell=True)\n",
        "\n",
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "print(\"Loading MNIST Dataset......\")\n",
        "f = np.load('mnist.npz')\n",
        "    \n",
        "x_train = torch.from_numpy(f['x_train'])\n",
        "y_train = torch.from_numpy(f['y_train']).long()\n",
        "x_test = torch.from_numpy(f['x_test'])\n",
        "y_test = torch.from_numpy(f['y_test']).long()\n",
        "\n",
        "f.close()\n",
        "\n",
        "torch.save((x_train, y_train), 'mnist_train.pt')\n",
        "torch.save((x_test, y_test), 'mnist_test.pt')\n",
        "print(\"Loading Finished\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading MNIST Dataset......\n",
            "Loading Finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfojzojwJn5t"
      },
      "source": [
        "This cell takes input from MNIST dataset and rotate each image and stores in a seperate data file for future use. Random angle is selected from the range and rotate each image with given angle and stores in the file in format (angle, x_data, y_data). Considering we focus on 20 different set of images that is 20 tasks. Therefore for a single task, all the 60k images from training set and all the 10k images from test set are rotated to an angle and stored correspoing to that task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vovpGSVP54Z2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "7014b1bb-780e-4ceb-b9ee-eadbe0dd51d0"
      },
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import os.path\n",
        "import random\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "tasks_tr = []\n",
        "tasks_te = []\n",
        "\n",
        "x_tr, y_tr = torch.load(os.path.join('mnist_train.pt'))\n",
        "x_te, y_te = torch.load(os.path.join('mnist_test.pt'))\n",
        "\n",
        "num_tasks = 20\n",
        "min_angle = 0\n",
        "max_angle = 180\n",
        "\n",
        "def rotate_dataset(d, rotation):\n",
        "    result = torch.FloatTensor(d.size(0), 784)\n",
        "    tensor = transforms.ToTensor()\n",
        "\n",
        "    for i in range(d.size(0)):\n",
        "        img = Image.fromarray(d[i].numpy(), mode='L')\n",
        "        result[i] = tensor(img.rotate(rotation)).view(784)\n",
        "    return result\n",
        "\n",
        "\n",
        "for t in range(num_tasks):\n",
        "    min_rot = 1.0 * t / num_tasks * (max_angle - min_angle) + min_angle\n",
        "    max_rot = 1.0 * (t + 1) / num_tasks * (max_angle - min_angle) + min_angle\n",
        "    rot = random.random() * (max_rot - min_rot) + min_rot\n",
        "    tasks_tr.append([rot, rotate_dataset(x_tr, rot), y_tr])\n",
        "    tasks_te.append([rot, rotate_dataset(x_te, rot), y_te])\n",
        "    print(\"Rotation angle : \" ,rot)\n",
        "\n",
        "torch.save([tasks_tr, tasks_te], 'mnist_rotation.pt')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rotation angle :  0.8907694362773108\n",
            "Rotation angle :  9.296451270586154\n",
            "Rotation angle :  18.75783163925422\n",
            "Rotation angle :  27.56881547567297\n",
            "Rotation angle :  43.377329291612504\n",
            "Rotation angle :  48.57667303018247\n",
            "Rotation angle :  58.450121163627266\n",
            "Rotation angle :  68.26619119933564\n",
            "Rotation angle :  76.76213652334327\n",
            "Rotation angle :  86.89617310027629\n",
            "Rotation angle :  91.02546422598101\n",
            "Rotation angle :  103.84053417517347\n",
            "Rotation angle :  112.37376115794072\n",
            "Rotation angle :  119.5483390566128\n",
            "Rotation angle :  132.24448438633794\n",
            "Rotation angle :  135.9533383218581\n",
            "Rotation angle :  147.81704046175864\n",
            "Rotation angle :  153.4463945876474\n",
            "Rotation angle :  162.91302168813965\n",
            "Rotation angle :  174.92692642576398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-gZ__ETLIHB"
      },
      "source": [
        "This cell takes input from MNIST dataset and permutes images and stores in the seperate file mnist_permutation.pt in the formate (random_permutation, x_data, y_data). Again for this dataset also, number of tasks are taken as 20. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64hU2kFl-ngk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "05e06205-6c5d-4701-ed3e-536407155dde"
      },
      "source": [
        "\n",
        "tasks_tr = []\n",
        "tasks_te = []\n",
        "\n",
        "num_tasks = 20\n",
        "\n",
        "print(\"Permutation of MNIST...\")\n",
        "x_tr, y_tr = torch.load(os.path.join('mnist_train.pt'))\n",
        "x_te, y_te = torch.load(os.path.join('mnist_test.pt'))\n",
        "x_tr = x_tr.float().view(x_tr.size(0), -1) / 255.0\n",
        "x_te = x_te.float().view(x_te.size(0), -1) / 255.0\n",
        "y_tr = y_tr.view(-1).long()\n",
        "y_te = y_te.view(-1).long()\n",
        "\n",
        "for t in range(num_tasks):\n",
        "    p = torch.randperm(x_tr.size(1)).long().view(-1)\n",
        "\n",
        "    tasks_tr.append(['random permutation', x_tr.index_select(1, p), y_tr])\n",
        "    tasks_te.append(['random permutation', x_te.index_select(1, p), y_te])\n",
        "\n",
        "torch.save([tasks_tr, tasks_te], 'mnist_permutation.pt')\n",
        "print(\"File saved\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Permutation of MNIST...\n",
            "File saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWRmEy3KL62m"
      },
      "source": [
        "This cell loads mnist_rotation and mnist_permutation dataset and stores in the variable training, testing, input, output, tasks. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Kp7tbYPZy1F"
      },
      "source": [
        "def load_datasets(inputfile):\n",
        "    d_tr, d_te = torch.load(inputfile)\n",
        "    n_inputs = d_tr[0][1].size(1)\n",
        "    n_outputs = 0\n",
        "    for i in range(len(d_tr)):\n",
        "        n_outputs = max(n_outputs, d_tr[i][2].max().item())\n",
        "        n_outputs = max(n_outputs, d_te[i][2].max().item())\n",
        "    return d_tr, d_te, n_inputs, n_outputs + 1, len(d_tr)\n",
        "\n",
        "rot_train, rot_test, rot_n_inputs, rot_n_outputs, rot_n_tasks = load_datasets('mnist_rotation.pt')\n",
        "per_train, per_test, per_n_inputs, per_n_outputs, per_n_tasks = load_datasets('mnist_permutation.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDROmwOAYMXn"
      },
      "source": [
        "Continuum class is used to generate continuous data stream. Varibale samples_per_task controls switching between the tasks after samples are taken. \n",
        "\n",
        "rot_train => Rotated training dataset\n",
        "\n",
        "rot_test => Rotated testing dataset\n",
        "\n",
        "per_train => Permuted training dataset\n",
        "\n",
        "per_test => Permuted testing dataset\n",
        "\n",
        "rot_n_inputs = per_n_inputs => 784 which is 28x28\n",
        "\n",
        "rot_n_outputs = per_n_outputs => 10 which is 10\n",
        "\n",
        "rot_n_tasks = per_n_tasks => 20\n",
        "\n",
        "Continuum returns 10 images everytime when called and changes to next task when it crosses samples_per_task. After every 1000 images task descriptor changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ensDFXnCaCRF"
      },
      "source": [
        "batch_size = 10\n",
        "samples_per_task = 1000\n",
        "n_epochs = 10\n",
        "shuffle_tasks = \"no\"\n",
        "\n",
        "class Continuum:\n",
        "\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        n_tasks = len(data)\n",
        "        task_permutation = range(n_tasks)\n",
        "\n",
        "        if shuffle_tasks == 'yes':\n",
        "            task_permutation = torch.randperm(n_tasks).tolist()\n",
        "\n",
        "        sample_permutations = []\n",
        "\n",
        "        for t in range(n_tasks):\n",
        "            N = data[t][1].size(0)\n",
        "            if samples_per_task <= 0:\n",
        "                n = N\n",
        "            else:\n",
        "                n = min(samples_per_task, N)\n",
        "            p = torch.randperm(N)[0:n]\n",
        "            sample_permutations.append(p)\n",
        "\n",
        "        self.permutation = []\n",
        "\n",
        "        for t in range(n_tasks):\n",
        "            task_t = task_permutation[t]\n",
        "            for _ in range(n_epochs):\n",
        "                task_p = [[task_t, i] for i in sample_permutations[task_t]]\n",
        "                random.shuffle(task_p)\n",
        "                self.permutation += task_p\n",
        "\n",
        "        self.length = len(self.permutation)\n",
        "        self.current = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def next(self):\n",
        "        return self.__next__()\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.current >= self.length:\n",
        "            raise StopIteration\n",
        "        else:\n",
        "            ti = self.permutation[self.current][0]\n",
        "            j = []\n",
        "            i = 0\n",
        "            while (((self.current + i) < self.length) and\n",
        "                   (self.permutation[self.current + i][0] == ti) and\n",
        "                   (i < self.batch_size)):\n",
        "                j.append(self.permutation[self.current + i][1])\n",
        "                i += 1\n",
        "            self.current += i\n",
        "            j = torch.LongTensor(j)\n",
        "            return self.data[ti][1][j], ti, self.data[ti][2][j]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjQx_6fkWcSw"
      },
      "source": [
        "This cell makes common layered network architecture for both single network and GEM network. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjpky-ITcky5"
      },
      "source": [
        "import math\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import relu, avg_pool2d\n",
        "\n",
        "n_layers = 2\n",
        "n_hiddens = 100\n",
        "\n",
        "def fun(m):\n",
        "    if m.__class__.__name__ == 'Linear':\n",
        "        fan_in, fan_out = m.weight.data.size(1), m.weight.data.size(0)\n",
        "        std = 1.0 * math.sqrt(2.0 / (fan_in + fan_out))\n",
        "        a = math.sqrt(3.0) * std\n",
        "        m.weight.data.uniform_(-a, a)\n",
        "        m.bias.data.fill_(0.0)\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, sizes):\n",
        "        super(MLP, self).__init__()\n",
        "        layers = []\n",
        "\n",
        "        for i in range(0, len(sizes) - 1):\n",
        "            layers.append(nn.Linear(sizes[i], sizes[i + 1]))\n",
        "            if i < (len(sizes) - 2):\n",
        "                layers.append(nn.ReLU())\n",
        "\n",
        "        self.net = nn.Sequential(*layers)\n",
        "        self.net.apply(fun)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_LAJlPdYgq8"
      },
      "source": [
        "This cell defines the structure of Simple network for classification.\n",
        "Given number of inputs, number of outputs and total tasks. For a given task, this model learns the weights associated for that task and predicts well on the same task test data but training on different tasks it overwrites the previously learned weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0zr3wj2lvcj"
      },
      "source": [
        "learning_simple = 0.3\n",
        "class SimpleNet(torch.nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_inputs,\n",
        "                 n_outputs,\n",
        "                 n_tasks):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        nl, nh = n_layers, n_hiddens\n",
        "        self.net = MLP([n_inputs] + [nh] * nl + [n_outputs])\n",
        "        self.opt = torch.optim.SGD(self.parameters(), lr=learning_simple)\n",
        "        self.bce = torch.nn.CrossEntropyLoss()\n",
        "        self.nc_per_task = n_outputs\n",
        "        \n",
        "    def compute_offsets(self, task):\n",
        "        offset1 = 0\n",
        "        offset2 = self.n_outputs\n",
        "        return int(offset1), int(offset2)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        output = self.net(x)\n",
        "        return output\n",
        "\n",
        "    def observe(self, x, t, y):\n",
        "        self.train()\n",
        "        self.zero_grad()\n",
        "        self.bce(self(x, t), y).backward()\n",
        "        self.opt.step()\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCobqnXsC7Lm"
      },
      "source": [
        "This cell represents gradient episodic memory algorithm described in the paper : http://papers.nips.cc/paper/7225-gradient-episodic-memory-for-continual-learning.pdf\n",
        "\n",
        "When observing new task, it is first checked whether this task is new task then the previous one or not. 2 tensors are kept to store data and labels assigned. Memory counter is kept to track the next position to store new data and when this counter reaches to the maximum meory, it starts overwrites from the beginning. \n",
        "\n",
        "When the new tasks come, algorithm first goes through all the previous learned tasks and calculates the gradients and stores them for future calculations. \n",
        "Then it learns new task and calculate gradients. Idea is to keep the loss on the current task less while keeping in mind that the sum of losses on previous tasks using this model should be less then sum of losses on previous tasks using previous best model. If this condition violates, it calculates projection of the new gradients on each of the previously leanred gradients and overwrites. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz2kq1XFN4Ul"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import quadprog\n",
        "\n",
        "def compute_offsets(task, nc_per_task):\n",
        "    offset1 = 0\n",
        "    offset2 = nc_per_task\n",
        "    return offset1, offset2\n",
        "\n",
        "def store_grad(pp, grads, grad_dims, tid):\n",
        "    grads[:, tid].fill_(0.0)\n",
        "    cnt = 0\n",
        "    for param in pp():\n",
        "        if param.grad is not None:\n",
        "            beg = 0 if cnt == 0 else sum(grad_dims[:cnt])\n",
        "            en = sum(grad_dims[:cnt + 1])\n",
        "            grads[beg: en, tid].copy_(param.grad.data.view(-1))\n",
        "        cnt += 1\n",
        "\n",
        "def overwrite_grad(pp, newgrad, grad_dims):\n",
        "    cnt = 0\n",
        "    for param in pp():\n",
        "        if param.grad is not None:\n",
        "            beg = 0 if cnt == 0 else sum(grad_dims[:cnt])\n",
        "            en = sum(grad_dims[:cnt + 1])\n",
        "            this_grad = newgrad[beg: en].contiguous().view(\n",
        "                param.grad.data.size())\n",
        "            param.grad.data.copy_(this_grad)\n",
        "        cnt += 1\n",
        "\n",
        "def project2cone2(gradient, memories, margin=0.5, eps=1e-3):\n",
        "    memories_np = memories.cpu().t().double().numpy()\n",
        "    gradient_np = gradient.cpu().contiguous().view(-1).double().numpy()\n",
        "    t = memories_np.shape[0]\n",
        "    P = np.dot(memories_np, memories_np.transpose())\n",
        "    P = 0.5 * (P + P.transpose()) + np.eye(t) * eps\n",
        "    q = np.dot(memories_np, gradient_np) * -1\n",
        "    G = np.eye(t)\n",
        "    h = np.zeros(t) + margin\n",
        "    v = quadprog.solve_qp(P, q, G, h)[0]\n",
        "    x = np.dot(v, memories_np) + gradient_np\n",
        "    gradient.copy_(torch.Tensor(x).view(-1, 1))\n",
        "\n",
        "n_layers = 2\n",
        "n_hiddens = 100\n",
        "memory_strength = 0.5\n",
        "learning_rate = 0.1\n",
        "n_memories = 256\n",
        "isCuda = 'yes'\n",
        "\n",
        "class GEMNet(nn.Module):\n",
        "    def __init__(self,\n",
        "                 n_inputs,\n",
        "                 n_outputs,\n",
        "                 n_tasks):\n",
        "        super(GEMNet, self).__init__()\n",
        "        nl, nh = n_layers, n_hiddens\n",
        "        self.margin = memory_strength\n",
        "        self.net = MLP([n_inputs] + [nh] * nl + [n_outputs])\n",
        "        self.ce = nn.CrossEntropyLoss()\n",
        "        self.n_outputs = n_outputs\n",
        "        self.opt = optim.SGD(self.parameters(), learning_rate)\n",
        "        self.n_memories = n_memories\n",
        "        self.gpu = isCuda\n",
        "        self.memory_data = torch.FloatTensor(\n",
        "            n_tasks, self.n_memories, n_inputs)\n",
        "        self.memory_labs = torch.LongTensor(n_tasks, self.n_memories)\n",
        "        if isCuda:\n",
        "            self.memory_data = self.memory_data.cuda()\n",
        "            self.memory_labs = self.memory_labs.cuda()\n",
        "        self.grad_dims = []\n",
        "        for param in self.parameters():\n",
        "            self.grad_dims.append(param.data.numel())\n",
        "        self.grads = torch.Tensor(sum(self.grad_dims), n_tasks)\n",
        "        if isCuda:\n",
        "            self.grads = self.grads.cuda()\n",
        "        self.observed_tasks = []\n",
        "        self.old_task = -1\n",
        "        self.mem_cnt = 0\n",
        "        self.nc_per_task = n_outputs\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        output = self.net(x)\n",
        "        return output\n",
        "\n",
        "    def observe(self, x, t, y):\n",
        "        if t != self.old_task:\n",
        "            self.observed_tasks.append(t)\n",
        "            self.old_task = t\n",
        "        bsz = y.data.size(0)\n",
        "        endcnt = min(self.mem_cnt + bsz, self.n_memories)\n",
        "        effbsz = endcnt - self.mem_cnt\n",
        "        self.memory_data[t, self.mem_cnt: endcnt].copy_(\n",
        "            x.data[: effbsz])\n",
        "        if bsz == 1:\n",
        "            self.memory_labs[t, self.mem_cnt] = y.data[0]\n",
        "        else:\n",
        "            self.memory_labs[t, self.mem_cnt: endcnt].copy_(\n",
        "                y.data[: effbsz])\n",
        "        self.mem_cnt += effbsz\n",
        "        if self.mem_cnt == self.n_memories:\n",
        "            self.mem_cnt = 0\n",
        "        if len(self.observed_tasks) > 1:\n",
        "            for tt in range(len(self.observed_tasks) - 1):\n",
        "                self.zero_grad()\n",
        "                past_task = self.observed_tasks[tt]\n",
        "\n",
        "                offset1, offset2 = compute_offsets(past_task, self.nc_per_task)\n",
        "                ptloss = self.ce(\n",
        "                    self.forward(\n",
        "                        self.memory_data[past_task],\n",
        "                        past_task)[:, offset1: offset2],\n",
        "                    self.memory_labs[past_task] - offset1)\n",
        "                ptloss.backward()\n",
        "                store_grad(self.parameters, self.grads, self.grad_dims,\n",
        "                           past_task)\n",
        "        self.zero_grad()\n",
        "\n",
        "        offset1, offset2 = compute_offsets(t, self.nc_per_task)\n",
        "        loss = self.ce(self.forward(x, t)[:, offset1: offset2], y - offset1)\n",
        "        loss.backward()\n",
        "        if len(self.observed_tasks) > 1:\n",
        "            store_grad(self.parameters, self.grads, self.grad_dims, t)\n",
        "            indx = torch.cuda.LongTensor(self.observed_tasks[:-1]) if self.gpu \\\n",
        "                else torch.LongTensor(self.observed_tasks[:-1])\n",
        "            dotp = torch.mm(self.grads[:, t].unsqueeze(0),\n",
        "                            self.grads.index_select(1, indx))\n",
        "            if (dotp < 0).sum() != 0:\n",
        "                project2cone2(self.grads[:, t].unsqueeze(1),\n",
        "                              self.grads.index_select(1, indx), self.margin)\n",
        "                overwrite_grad(self.parameters, self.grads[:, t],\n",
        "                               self.grad_dims)\n",
        "        self.opt.step()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE0ot-0NZ8SI"
      },
      "source": [
        "Life-Experience : This function takes input as continuum, model and test dataset as input and trains the model. When the task changes, eval_tasks function is called to measure performance fluctuations in all tasks because of the update and measures accuracy on all the tasks and stores in the results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwBGtZ5GN4PE"
      },
      "source": [
        "def eval_tasks(model, tasks):\n",
        "    model.eval()\n",
        "    result = []\n",
        "    for i, task in enumerate(tasks):\n",
        "        t = i\n",
        "        x = task[1]\n",
        "        y = task[2]\n",
        "        rt = 0\n",
        "        \n",
        "        eval_bs = x.size(0)\n",
        "\n",
        "        for b_from in range(0, x.size(0), eval_bs):\n",
        "            b_to = min(b_from + eval_bs, x.size(0) - 1)\n",
        "            if b_from == b_to:\n",
        "                xb = x[b_from].view(1, -1)\n",
        "                yb = torch.LongTensor([y[b_to]]).view(1, -1)\n",
        "            else:\n",
        "                xb = x[b_from:b_to]\n",
        "                yb = y[b_from:b_to]\n",
        "            if isCuda:\n",
        "                xb = xb.cuda()\n",
        "            _, pb = torch.max(model(xb, t).data.cpu(), 1, keepdim=False)\n",
        "            rt += (pb == yb).float().sum()\n",
        "\n",
        "        result.append(rt / x.size(0))\n",
        "\n",
        "    return result\n",
        "\n",
        "log_every = 100\n",
        "def life_experience(model, continuum, x_te):\n",
        "    result_a = []\n",
        "    result_t = []\n",
        "\n",
        "    current_task = 0\n",
        "    time_start = time.time()\n",
        "\n",
        "    for (i, (x, t, y)) in enumerate(continuum):\n",
        "        if(((i % log_every) == 0) or (t != current_task)):\n",
        "            result_a.append(eval_tasks(model, x_te))\n",
        "            result_t.append(current_task)\n",
        "            current_task = t\n",
        "\n",
        "        v_x = x.view(x.size(0), -1)\n",
        "        v_y = y.long()\n",
        "\n",
        "        if isCuda:\n",
        "            v_x = v_x.cuda()\n",
        "            v_y = v_y.cuda()\n",
        "\n",
        "        model.train()\n",
        "        model.observe(v_x, t, v_y)\n",
        "\n",
        "    result_a.append(eval_tasks(model, x_te))\n",
        "    result_t.append(current_task)\n",
        "\n",
        "    time_end = time.time()\n",
        "    time_spent = time_end - time_start\n",
        "\n",
        "    return torch.Tensor(result_t), torch.Tensor(result_a), time_spent\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCycOjkqbI8J"
      },
      "source": [
        "After getting information on accuracy fluctuations because of training new tasks, confusion matrix measures 4 important quantities from the matrix. \n",
        "\n",
        "1) Average accuracy : As it can be seen when a task is trained on the model, it will perform well on the same task test data but poor on other task test data. So taking average of all the diagonal elements will give the average accuracy of the model on the same task when it is trained on it.\n",
        "\n",
        "2) Final accuracy : This represents the accuracy of the model on all the test tasks after learning all the tasks. Higher the average final value, better continual model it is. \n",
        " \n",
        "3) BWT (Backward transfer) : Performance change on previous tasks when the model finishes training on all tasks, that is R[T, t]- R[t,t]\n",
        "\n",
        "4) FWT (Forward trasnfer) : Performance change on future tasks after learning the current task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r0PkEsRD7BD"
      },
      "source": [
        "def task_changes(result_t):\n",
        "    n_tasks = int(result_t.max() + 1)\n",
        "    changes = []\n",
        "    current = result_t[0]\n",
        "    for i, t in enumerate(result_t):\n",
        "        if t != current:\n",
        "            changes.append(i)\n",
        "            current = t\n",
        "\n",
        "    return n_tasks, changes\n",
        "\n",
        "\n",
        "def confusion_matrix(result_t, result_a, fname=None):\n",
        "    nt, changes = task_changes(result_t)\n",
        "\n",
        "    baseline = result_a[0]\n",
        "    changes = torch.LongTensor(changes + [result_a.size(0)]) - 1\n",
        "    result = result_a[changes]\n",
        "\n",
        "    # acc[t] equals result[t,t]\n",
        "    acc = result.diag()\n",
        "    fin = result[nt - 1]\n",
        "    # bwt[t] equals result[T,t] - acc[t]\n",
        "    bwt = result[nt - 1] - acc\n",
        "\n",
        "    # fwt[t] equals result[t-1,t] - baseline[t]\n",
        "    fwt = torch.zeros(nt)\n",
        "    for t in range(1, nt):\n",
        "        fwt[t] = result[t - 1, t] - baseline[t]\n",
        "\n",
        "    if fname is not None:\n",
        "        f = open(fname, 'w')\n",
        "\n",
        "        print(' '.join(['%.4f' % r for r in baseline]), file=f)\n",
        "        print('|', file=f)\n",
        "        for row in range(result.size(0)):\n",
        "            print(' '.join(['%.4f' % r for r in result[row]]), file=f)\n",
        "        print('', file=f)\n",
        "        # print('Diagonal Accuracy: %.4f' % acc.mean(), file=f)\n",
        "        print('Final Accuracy: %.4f' % fin.mean(), file=f)\n",
        "        print('Backward: %.4f' % bwt.mean(), file=f)\n",
        "        print('Forward:  %.4f' % fwt.mean(), file=f)\n",
        "        f.close()\n",
        "\n",
        "    stats = []\n",
        "    stats.append(acc.mean())\n",
        "    stats.append(fin.mean())\n",
        "    stats.append(bwt.mean())\n",
        "    stats.append(fwt.mean())\n",
        "\n",
        "    return stats\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DLQVjRJf4R8"
      },
      "source": [
        "Continuum defination, model declaration, model training and parameter calculation for all the 4 tasks on 2 models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwgDaI3asSDC"
      },
      "source": [
        "import time\n",
        "rot_continuum = Continuum(rot_train)\n",
        "\n",
        "rot_simple_model = SimpleNet(rot_n_inputs, rot_n_outputs, rot_n_tasks)\n",
        "rot_simple_model.cuda()\n",
        "\n",
        "rot_simple_result_t, rot_simple_result_a, rot_simple_spent_time = life_experience(rot_simple_model, rot_continuum, rot_test)\n",
        "rot_simple_stats = confusion_matrix(rot_simple_result_t, rot_simple_result_a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BOqkqWtlvUy"
      },
      "source": [
        "per_continuum = Continuum(per_train)\n",
        "\n",
        "per_simple_model = SimpleNet(per_n_inputs, per_n_outputs, per_n_tasks)\n",
        "per_simple_model.cuda()\n",
        "\n",
        "per_simple_result_t, per_simple_result_a, per_simple_spent_time = life_experience(per_simple_model, per_continuum, per_test)\n",
        "per_simple_stats = confusion_matrix(rot_simple_result_t, rot_simple_result_a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcTkMVIfD69q"
      },
      "source": [
        "rot_continuum = Continuum(rot_train)\n",
        "\n",
        "rot_gem_model = GEMNet(rot_n_inputs, rot_n_outputs, rot_n_tasks)\n",
        "rot_gem_model.cuda()\n",
        "\n",
        "rot_gem_result_t, rot_gem_result_a, rot_gem_spent_time = life_experience(rot_gem_model, rot_continuum, rot_test)\n",
        "rot_gem_stats = confusion_matrix(rot_gem_result_t, rot_gem_result_a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnrTVYUUD63K"
      },
      "source": [
        "per_continuum = Continuum(per_train)\n",
        "\n",
        "per_gem_model = GEMNet(per_n_inputs, per_n_outputs, per_n_tasks)\n",
        "per_gem_model.cuda()\n",
        "\n",
        "per_gem_result_t, per_gem_result_a, per_gem_spent_time = life_experience(per_gem_model, per_continuum, per_test)\n",
        "per_gem_stats = confusion_matrix(per_gem_result_t, per_gem_result_a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEH85Fz8-t-"
      },
      "source": [
        "Observation of the parameters : Where values are\n",
        "\n",
        "Average accuracy, Final accuracy, Backward trasnfer, Forward trasnfer respectively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnJ0MHg9lu8L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1a1a14fb-c300-43cb-f9ed-c69e2f1cf3e4"
      },
      "source": [
        "print(rot_simple_stats)\n",
        "print(rot_gem_stats)\n",
        "print(per_simple_stats)\n",
        "print(per_gem_stats)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor(0.9001), tensor(0.3665), tensor(-0.5336), tensor(0.7087)]\n",
            "[tensor(0.9070), tensor(0.8857), tensor(-0.0213), tensor(0.7311)]\n",
            "[tensor(0.9001), tensor(0.3665), tensor(-0.5336), tensor(0.7087)]\n",
            "[tensor(0.8930), tensor(0.8459), tensor(-0.0471), tensor(0.0022)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r0f9v1w4SmS"
      },
      "source": [
        "Below graphs show the performance improvement by using Gradient episodic memory algorithm. First bar represents accuracy of simple model and second bar represents of GEM model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVrcfFGTm1-Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "44c4eb5b-26d0-49da-b5c3-76a72afe3eb3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rot_final_accuracy = []\n",
        "per_final_accuracy = []\n",
        "dataset = ['Simple', 'GEM']\n",
        "y_pos = np.arange(len(dataset))\n",
        "\n",
        "rot_final_accuracy.append(rot_simple_stats[1])\n",
        "rot_final_accuracy.append(rot_gem_stats[1])\n",
        "\n",
        "per_final_accuracy.append(per_simple_stats[1])\n",
        "per_final_accuracy.append(per_gem_stats[1])\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(y_pos, rot_final_accuracy)\n",
        "plt.xticks(y_pos, dataset)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(y_pos, per_final_accuracy)\n",
        "plt.xticks(y_pos, dataset)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLosIOdz+3EgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar-o4-hVm1jf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}